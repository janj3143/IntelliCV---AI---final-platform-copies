{
  "file_id": "file_361502815f91",
  "source_path": "C:\\IntelliCV\\data\\# File corecv_matcher_advanced double check.txt",
  "extracted_at": "2025-08-10T16:08:56.633109",
  "text": "# File: core/cv_matcher_advanced.py\n\nimport os\nimport json\nimport re\nfrom pathlib import Path\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n\ndef load_file(path):\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            return f.read()\n    except FileNotFoundError:\n        return None\n\n\ndef clean_text(text):\n    text = re.sub(r\"\\s+\", \" \", text)\n    return text.strip().lower()\n\n\nif __name__ == \"__main__\":\n    resume_text = load_file(\"data/user_resume.txt\")\n    job_text = load_file(\"data/job_description.txt\")\n\n    result = {\n        \"mode\": \"cv_only\",\n        \"match_score\": None,\n        \"matched_keywords\": [],\n        \"note\": \"No job description provided. CV analyzed independently.\"\n    }\n\n    if resume_te # File: core/cv_matcher_advanced.py\n\nimport os\nimport json\nimport re\nfrom pathlib import Path\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n\ndef load_file(path):\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            return f.read()\n    except FileNotFoundError:\n        return None\n\n\ndef clean_text(text):\n    text = re.sub(r\"\\s+\", \" \", text)\n    return text.strip().lower()\n\n\nif __name__ == \"__main__\":\n    resume_text = load_file(\"data/user_resume.txt\")\n    job_text = load_file(\"data/job_description.txt\")\n\n    result = {\n        \"mode\": \"cv_only\",\n        \"match_score\": None,\n        \"matched_keywords\": [],\n        \"note\": \"No job description provided. CV analyzed independently.\"\n    }\n\n    if resume_text:\n        resume_text_cleaned = clean_text(resume_text)\n\n        if job_text:\n            job_text_cleaned = clean_text(job_text)\n            vectorizer = TfidfVectorizer(stop_words=\"english\")\n            vectors = vectorizer.fit_transform([resume_text_cleaned, job_text_cleaned])\n            score = cosine_similarity(vectors[0:1], vectors[1:2])[0][0] * 100\n\n            matched = set(word for word in job_text_cleaned.split() if word in resume_text_cleaned)\n            result = {\n                \"mode\": \"cv_to_job\",\n                \"match_score\": round(score, 2),\n                \"matched_keywords\": list(matched),\n                \"note\": \"Match score calculated against provided job description.\"\n            }\n\n    with open(\"output/match_analysis.json\", \"w\", encoding=\"utf-8\") as f:\n        json.dump(result, f, indent=2)\n\n    print(\"[MATCHER] Analysis complete.\")\n\nNew CV Matcher\n# File: core/cv_tuner_advanced.py\n\nimport json\nfrom pathlib import Path\nfrom spacy.lang.en import English\nfrom spacy.matcher import PhraseMatcher\n\nnlp = English()\nmatcher = PhraseMatcher(nlp.vocab)\n\n# Expanded keywords to suggest\nbuzzwords = [\n    \"kubernetes\", \"sql\", \"cloud\", \"python\", \"leadership\",\n    \"apis\", \"data\", \"infrastructure\", \"scalability\", \"automation\",\n    \"microservices\", \"machine learning\", \"digital transformation\",\n    \"carbon capture\", \"energy transition\", \"stakeholder engagement\",\n    \"technical marketing\", \"R&D\", \"technology licensing\"\n]\n\npatterns = [nlp.make_doc(text) for text in buzzwords]\nmatcher.add(\"BUZZWORDS\", patterns)\n\ncv_path = Path(\"data/user_resume.txt\")\nif not cv_path.exists():\n    print(\"⚠️ Resume not found.\")\n    exit()\n\ntext = cv_path.read_text(encoding=\"utf-8\")\ndoc = nlp(text.lower())\n\nfound_keywords = set([str(span).lower() for match_id, start, end in matcher(doc) for span in [doc[start:end]]])\nsuggestions = [w for w in buzzwords if w not in found_keywords]\n\nresult = {\n    \"found\": sorted(list(found_keywords)),\n    \"recommendations\": suggestions\n}\n\nPath(\"output/tuned_cv_recommendations.json\").write_text(json.dumps(result, indent=2))\nprint(\"✅ CV tuning completed.\")\n ",
  "emails": [],
  "phones": [],
  "names": [],
  "work_history": [],
  "skills": []
}